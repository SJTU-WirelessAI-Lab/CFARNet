# CFARNet: Learning-Based High-Resolution Multi-Target Detection for Rainbow Beam Radar / åŸºäºæ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæ–¹æ³•çš„é›·è¾¾ä¿¡å·å‚æ•°ç”Ÿæˆä¸ç›®æ ‡æ£€æµ‹å·¥å…·é“¾

## Related Publication

ğŸ“„ **Paper**: [CFARNet: Learning-Based High-Resolution Multi-Target Detection for Rainbow Beam Radar](https://arxiv.org/abs/2505.10150)

*Qiushi Liang, Yeyue Cai, Jianhua Mo, Meixia Tao*

This repository provides the implementation for the CFARNet paper, which presents a learning-based processing framework that replaces CFAR with a convolutional neural network (CNN) for peak detection in the angle-Doppler domain.

---

## Introduction / é¡¹ç›®ç®€ä»‹

CFARNet aims to provide a complete toolchain for radar signal processing and target detection, including simulation, data generation, deep learning training, and comparison with traditional methods. It supports high-quality yecho channel parameter generation, CNN-based target detection training, and baseline comparisons with traditional methods like CFAR+MUSIC.

CFARNetæ—¨åœ¨ä¸ºé›·è¾¾ä¿¡å·å¤„ç†å’Œç›®æ ‡æ£€æµ‹æä¾›ä¸€å¥—å®Œæ•´çš„ä»¿çœŸã€æ•°æ®ç”Ÿæˆã€æ·±åº¦å­¦ä¹ è®­ç»ƒä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”çš„å·¥å…·é“¾ã€‚æ”¯æŒé«˜è´¨é‡yechoä¿¡é“å‚æ•°ç”Ÿæˆã€åŸºäºCNNçš„ç›®æ ‡æ£€æµ‹è®­ç»ƒï¼Œä»¥åŠCFAR+MUSICç­‰ä¼ ç»Ÿæ–¹æ³•çš„baselineå¯¹æ¯”ã€‚

---

## File Structure and Function Description / æ–‡ä»¶ç»“æ„ä¸åŠŸèƒ½è¯´æ˜

| Filename / æ–‡ä»¶å | Main Function Description / ä¸»è¦åŠŸèƒ½æè¿° |
|-------------------|-------------------------------------------|
| `data_generation.py` | Generate yecho channel parameters, target trajectories, and system parameters with batch simulation and dataset generation support.<br>ç”Ÿæˆyechoä¿¡é“å‚æ•°ã€ç›®æ ‡è¿åŠ¨è½¨è¿¹ã€ç³»ç»Ÿå‚æ•°ç­‰ï¼Œæ”¯æŒæ‰¹é‡ä»¿çœŸå’Œæ•°æ®é›†ç”Ÿæˆã€‚ |
| `trajectory.py` | Target trajectory generation module supporting various motion patterns and parameter configurations.<br>ç›®æ ‡è¿åŠ¨è½¨è¿¹ç”Ÿæˆæ¨¡å—ï¼Œæ”¯æŒå¤šç§è¿åŠ¨æ¨¡å¼å’Œå‚æ•°é…ç½®ã€‚ |
| `train.py` | Main deep learning model training script supporting CNN training, validation, testing, and visualization.<br>æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒä¸»è„šæœ¬ï¼Œæ”¯æŒCNNç­‰æ¨¡å‹çš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ä¸å¯è§†åŒ–ã€‚ |
| `CFARNet.py` | Parameter estimation using CNN+MUSIC vs traditional CFAR method comparison testing script.<br>åŸºäºCNN+MUSICçš„å‚æ•°ä¼°è®¡ä¸ä¼ ç»ŸCFARæ–¹æ³•å¯¹æ¯”æµ‹è¯•è„šæœ¬ã€‚ |
| `YOLO_baseline.py` | YOLO method target detection inference and evaluation script with various noise and parameter configurations.<br>YOLOæ–¹æ³•çš„ç›®æ ‡æ£€æµ‹æ¨ç†ä¸è¯„æµ‹è„šæœ¬ï¼Œæ”¯æŒå¤šç§å™ªå£°å’Œå‚æ•°é…ç½®ã€‚ |
| `functions.py` | Core utility function library including dataset loading, signal processing, feature extraction, and evaluation metrics.<br>æ ¸å¿ƒå·¥å…·å‡½æ•°åº“ï¼ŒåŒ…æ‹¬æ•°æ®é›†åŠ è½½ã€ä¿¡å·å¤„ç†ã€ç‰¹å¾æå–ã€è¯„æµ‹æŒ‡æ ‡ç­‰ã€‚ |
| `environment.yml` | Conda environment dependency configuration file containing all required packages and versions.<br>Condaç¯å¢ƒä¾èµ–é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰è¿è¡Œæ‰€éœ€çš„åŒ…å’Œç‰ˆæœ¬ã€‚ |
| `Readme.md` | Project documentation.<br>é¡¹ç›®è¯´æ˜æ–‡æ¡£ã€‚ |

---

## Quick Start / å¿«é€Ÿå¼€å§‹

### 1. Environment Setup / ç¯å¢ƒå‡†å¤‡

It is recommended to use Anaconda/Miniconda and execute the following commands to create the environment:

å»ºè®®ä½¿ç”¨Anaconda/Minicondaï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»ºç¯å¢ƒï¼š

```bash
conda env create -f environment.yml
conda activate isac
```

### 2. Data Generation / æ•°æ®ç”Ÿæˆ

Generate yecho channel parameters and target motion data:

ç”Ÿæˆyechoä¿¡é“å‚æ•°å’Œç›®æ ‡è¿åŠ¨æ•°æ®ï¼š

```bash
python data_generation.py --sample_num 5000 --chunk_size 500 --experiment_name my_exp
```

**Main Parameter Descriptions / ä¸»è¦å‚æ•°è¯´æ˜:**
- `--sample_num`: Number of samples to generate / ç”Ÿæˆæ ·æœ¬æ•°é‡
- `--chunk_size`: Number of samples per data chunk / æ¯ä¸ªæ•°æ®å—çš„æ ·æœ¬æ•°
- `--experiment_name`: Experiment name (for distinguishing data folders) / å®éªŒåç§°ï¼ˆç”¨äºåŒºåˆ†æ•°æ®æ–‡ä»¶å¤¹ï¼‰
- Other parameters see script comments and command line help / å…¶ä»–å‚æ•°è¯¦è§è„šæœ¬å†…æ³¨é‡Šå’Œå‘½ä»¤è¡Œå¸®åŠ©

### 3. Deep Learning Model Training / æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ

Train CNN and other deep learning models:

è®­ç»ƒCNNç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼š

```bash
python train.py --data_dir ./data/my_exp --batch_size 16 --epochs 50 --max_targets 3
```

**Main Parameter Descriptions / ä¸»è¦å‚æ•°è¯´æ˜:**
- `--data_dir`: Directory containing generated data / åŒ…å«ç”Ÿæˆæ•°æ®çš„ç›®å½•
- `--batch_size`: Training batch size / è®­ç»ƒæ‰¹æ¬¡å¤§å°
- `--epochs`: Number of training epochs / è®­ç»ƒè½®æ•°
- `--max_targets`: Maximum number of targets / æœ€å¤§ç›®æ ‡æ•°
- Other parameters see script comments and command line help / å…¶ä»–å‚æ•°è¯¦è§è„šæœ¬å†…æ³¨é‡Šå’Œå‘½ä»¤è¡Œå¸®åŠ©

### 4. Traditional CFAR+MUSIC Baseline Testing / ä¼ ç»ŸCFAR+MUSIC baselineæµ‹è¯•

Compare with traditional methods:

å¯¹æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼š

```bash
python CFARNet.py --data_dir ./data/my_exp --model_dir ./models/my_exp --top_k_cnn 3
```

**Main Parameter Descriptions / ä¸»è¦å‚æ•°è¯´æ˜:**
- `--data_dir`: Data directory / æ•°æ®ç›®å½•
- `--model_dir`: Trained model directory / è®­ç»ƒå¥½çš„æ¨¡å‹ç›®å½•
- `--top_k_cnn`: Top-K peaks from CNN output / CNNè¾“å‡ºçš„Top-Kå³°å€¼
- Other parameters see script comments and command line help / å…¶ä»–å‚æ•°è¯¦è§è„šæœ¬å†…æ³¨é‡Šå’Œå‘½ä»¤è¡Œå¸®åŠ©

### 5. YOLO Method Inference/Testing (Optional) / YOLOæ–¹æ³•æ¨ç†/æµ‹è¯•ï¼ˆå¯é€‰ï¼‰

```bash
python YOLO_baseline.py --data_dir ./data/my_exp --num_test_samples 1000
```

---

## Dependencies / ä¾èµ–ç¯å¢ƒ

- Python 3.10+
- numpy, torch, matplotlib, tqdm, scipy, torchvision, pandas, etc.
- Detailed dependencies see `environment.yml` / è¯¦ç»†ä¾èµ–è§ `environment.yml`

---

## Data Structure Description / æ•°æ®ç»“æ„è¯´æ˜

Generated data is saved in the specified directory, mainly including:

ç”Ÿæˆçš„æ•°æ®ä¿å­˜åœ¨æŒ‡å®šç›®å½•ä¸‹ï¼Œä¸»è¦åŒ…æ‹¬ï¼š

- `echoes/`: Chunked yecho channel parameters / åˆ†å—ä¿å­˜çš„yechoä¿¡é“å‚æ•°
- `trajectory_data.npz`: Target trajectories and peak indices / ç›®æ ‡è½¨è¿¹ä¸å³°å€¼ç´¢å¼•
- `system_params.npz`: System parameter configuration / ç³»ç»Ÿå‚æ•°é…ç½®

---

## Contribution and License / è´¡çŒ®ä¸è®¸å¯

We welcome anyone to submit PRs or issues to improve this project.

æ¬¢è¿ä»»ä½•äººæäº¤PRæˆ–issueæ”¹è¿›æœ¬é¡¹ç›®ã€‚

This project is licensed under the MIT License.

æœ¬é¡¹ç›®é‡‡ç”¨MITå¼€æºåè®®ã€‚

---

## Detailed File Descriptions / å„æ–‡ä»¶è¯¦ç»†è¯´æ˜

### data_generation.py
Mainly used for simulating radar echo signals (yecho), target trajectories, system parameters, etc. Supports batch generation and chunked storage for large-scale dataset creation. Allows customization of target numbers, motion patterns, noise parameters, etc.

ä¸»è¦ç”¨äºä»¿çœŸç”Ÿæˆé›·è¾¾å›æ³¢ä¿¡å·ï¼ˆyechoï¼‰ã€ç›®æ ‡è¿åŠ¨è½¨è¿¹ã€ç³»ç»Ÿå‚æ•°ç­‰ã€‚æ”¯æŒæ‰¹é‡ç”Ÿæˆã€åˆ†å—å­˜å‚¨ï¼Œä¾¿äºå¤§è§„æ¨¡æ•°æ®é›†åˆ¶ä½œã€‚å¯è‡ªå®šä¹‰ç›®æ ‡æ•°é‡ã€è¿åŠ¨æ¨¡å¼ã€å™ªå£°å‚æ•°ç­‰ã€‚

### trajectory.py
Responsible for generating 2D target trajectories, supporting circular, random, fixed-angle and other modes. Allows flexible configuration of target initial position, velocity, angle and other parameters.

è´Ÿè´£ç”Ÿæˆç›®æ ‡çš„äºŒç»´è¿åŠ¨è½¨è¿¹ï¼Œæ”¯æŒåœ†å½¢ã€éšæœºã€å›ºå®šè§’åº¦ç­‰å¤šç§æ¨¡å¼ã€‚å¯çµæ´»é…ç½®ç›®æ ‡åˆå§‹ä½ç½®ã€é€Ÿåº¦ã€è§’åº¦ç­‰å‚æ•°ã€‚

### train.py
Main deep learning training script supporting CNN and other model training, validation, and testing. Built-in multiple loss functions, evaluation metrics, and visualization tools. Supports checkpoint resumption and automatic experiment result saving.

æ·±åº¦å­¦ä¹ è®­ç»ƒä¸»è„šæœ¬ï¼Œæ”¯æŒCNNç­‰æ¨¡å‹çš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ã€‚å†…ç½®å¤šç§æŸå¤±å‡½æ•°ã€è¯„æµ‹æŒ‡æ ‡ã€å¯è§†åŒ–å·¥å…·ã€‚æ”¯æŒæ–­ç‚¹ç»­è®­ã€å®éªŒç»“æœè‡ªåŠ¨ä¿å­˜ã€‚

### CFARNet.py
Implements CNN+MUSIC-based parameter estimation method and compares with traditional CFAR methods. Supports batch testing, result visualization, and performance evaluation.

å®ç°åŸºäºCNN+MUSICçš„å‚æ•°ä¼°è®¡æ–¹æ³•ï¼Œå¹¶ä¸ä¼ ç»ŸCFARæ–¹æ³•è¿›è¡Œå¯¹æ¯”ã€‚æ”¯æŒæ‰¹é‡æµ‹è¯•ã€ç»“æœå¯è§†åŒ–ã€æ€§èƒ½è¯„ä¼°ã€‚

### YOLO_baseline.py
Implements YOLO method target detection inference and evaluation. Supports various noise and parameter configurations for comparison with deep learning methods.

å®ç°YOLOæ–¹æ³•çš„ç›®æ ‡æ£€æµ‹æ¨ç†ä¸è¯„æµ‹ã€‚æ”¯æŒå¤šç§å™ªå£°ã€å‚æ•°é…ç½®ï¼Œä¾¿äºä¸æ·±åº¦å­¦ä¹ æ–¹æ³•å¯¹æ¯”ã€‚

### functions.py
Provides core utility functions for dataset loading, signal processing, feature extraction, evaluation metrics, etc. Facilitates main process script calls and improves code reusability.

æä¾›æ•°æ®é›†åŠ è½½ã€ä¿¡å·å¤„ç†ã€ç‰¹å¾æå–ã€è¯„æµ‹æŒ‡æ ‡ç­‰æ ¸å¿ƒå·¥å…·å‡½æ•°ã€‚ä¾¿äºä¸»æµç¨‹è„šæœ¬è°ƒç”¨ï¼Œæå‡ä»£ç å¤ç”¨æ€§ã€‚

### environment.yml
Conda environment configuration containing all dependency packages and versions to ensure environment consistency.

Condaç¯å¢ƒé…ç½®ï¼ŒåŒ…å«æ‰€æœ‰ä¾èµ–åŒ…åŠç‰ˆæœ¬ï¼Œç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§ã€‚

---


